"use strict";(self.webpackChunkclarity=self.webpackChunkclarity||[]).push([[1009],{50684:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"cpc3/cpc3_data","title":"Data Specification","description":"The CPC3 data is derived from the first three Clarity Enhancement Challenges (CEC1, CEC2, and CEC3). The processed signals represent the outputs of the systems submitted by participants, and listener responses were collected during the evaluation of these systems.","source":"@site/docs/cpc3/cpc3_data.mdx","sourceDirName":"cpc3","slug":"/cpc3/cpc3_data","permalink":"/docs/cpc3/cpc3_data","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"cpc3_data","title":"Data Specification","sidebar_label":"Data Specification","sidebar_position":3},"sidebar":"tutorialSidebar_cpc3","previous":{"title":"Download Data","permalink":"/docs/cpc3/cpc3_download"},"next":{"title":"Baseline System","permalink":"/docs/cpc3/cpc3_baseline"}}');var s=t(74848),r=t(28453);const a={id:"cpc3_data",title:"Data Specification",sidebar_label:"Data Specification",sidebar_position:3},c=void 0,d={},l=[{value:"Overview",id:"overview",level:2},{value:"Hearing Aid Output Signals",id:"hearing-aid-output-signals",level:2},{value:"Reference Signals",id:"reference-signals",level:2},{value:"Metadata",id:"metadata",level:2},{value:"Listening Test Responses",id:"listening-test-responses",level:3},{value:"Listener Characteristics",id:"listener-characteristics",level:3}];function o(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.p,{children:"The CPC3 data is derived from the first three Clarity Enhancement Challenges (CEC1, CEC2, and CEC3). The processed signals represent the outputs of the systems submitted by participants, and listener responses were collected during the evaluation of these systems."}),"\n",(0,s.jsx)(n.admonition,{type:"info",children:(0,s.jsxs)(n.p,{children:["To obtain the data, please visit the ",(0,s.jsx)(n.a,{href:"./cpc3_download",children:"download page"}),"."]})}),"\n",(0,s.jsxs)(n.p,{children:["The data is distributed as a single gzipped tarball, ",(0,s.jsx)(n.code,{children:"clarity_CPC3_data.v1_0.tar.gz"}),", which unpacks into the following directory structure:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"clarity_CPC3_data\n\u251c\u2500\u2500 clarity_data\n\u2502   \u251c\u2500\u2500 metadata  # Metadata including listener responses and listener characteristics\n\u2502   \u2514\u2500\u2500 train\n\u2502       \u251c\u2500\u2500 references  # References for intrusive intelligibility prediction\n\u2502       \u2514\u2500\u2500 signals     # Hearing aid output signals\n\u2514\u2500\u2500 manifest\n"})}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"The training data comprises signals and their corresponding listener responses, which can be utilized to train a prediction model."}),"\n",(0,s.jsx)(n.p,{children:"It is important to note that some signals and responses originate from CEC1, while others come from CEC2. CEC1 focused on simple scenes with a single interferer, whereas CEC2 involved multiple interferers. The development and evaluation data will use systems and scenes from CEC3."}),"\n",(0,s.jsx)(n.h2,{id:"hearing-aid-output-signals",children:"Hearing Aid Output Signals"}),"\n",(0,s.jsxs)(n.p,{children:["The output signals from the hearing aid are located in the ",(0,s.jsx)(n.code,{children:"clarity_data/HA_output"})," directory. These signals are characterized by the input signal presented to the hearing aid (referred to as the 'scene'), the algorithm utilized by the hearing aid (known as the 'system'), and the listener for whom the algorithm has been tailored (called the 'listener')."]}),"\n",(0,s.jsx)(n.p,{children:"The signals are stored in 16-bit stereo WAV format with a sampling rate of 32 kHz. They are named according to the following convention:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"<CEC>_<SYSTEM_ID>_<SCENE_ID>_<LISTENER_ID>.wav  # Example: CEC1_E010_S09673_L0217.wav\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Where ",(0,s.jsx)(n.code,{children:"<CEC>"})," is the Clarity Enhancement Challenge identifier (either CEC1 or CEC2), ",(0,s.jsx)(n.code,{children:"<SYSTEM_ID>"})," is the hearing aid system identifier, ",(0,s.jsx)(n.code,{children:"<SCENE_ID>"})," is the scene identifier, and ",(0,s.jsx)(n.code,{children:"<LISTENER_ID>"})," is the listener identifier."]}),"\n",(0,s.jsx)(n.h2,{id:"reference-signals",children:"Reference Signals"}),"\n",(0,s.jsx)(n.p,{children:"Reference signals are provided for use in intrusive intelligibility prediction tasks. They represent the non-reverberant version of the target speech signals. These signals have been aligned and energy-scaled to match the target component of the signal received by the hearing aid. Note that they may be slightly misaligned with the hearing aid output signals due to the processing performed by the hearing aid, and intrusive models should be robust to this."}),"\n",(0,s.jsxs)(n.p,{children:["The reference signals are stored in the ",(0,s.jsx)(n.code,{children:"clarity_data/references"})," directory and are named as follows:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"<CEC_ID>_<SCENE_ID>_ref.wav  \n"})}),"\n",(0,s.jsxs)(n.p,{children:["Where ",(0,s.jsx)(n.code,{children:"<CEC_ID>"})," is the Clarity Enhancement Challenge identifier (either CEC1 or CEC2), and ",(0,s.jsx)(n.code,{children:"<SCENE_ID>"})," is the scene identifier."]}),"\n",(0,s.jsxs)(n.p,{children:["It is important to note that there is a many-to-one mapping of hearing aid outputs to reference signals. The reference signal ",(0,s.jsx)(n.code,{children:"<CEC_ID>_<SCENE_ID>_ref.wav"})," serves as the correct reference for all hearing aid outputs generated from the scene ",(0,s.jsx)(n.code,{children:"<SCENE_ID>"})," in the Clarity Enhancement Challenge ",(0,s.jsx)(n.code,{children:"<CEC_ID>"}),"."]}),"\n",(0,s.jsx)(n.h2,{id:"metadata",children:"Metadata"}),"\n",(0,s.jsxs)(n.p,{children:["The metadata directory (",(0,s.jsx)(n.code,{children:"clarity_data/metadata"}),") contains the listener responses to the signals as well as listener characteristics."]}),"\n",(0,s.jsx)(n.p,{children:"You will find the following files:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"CPC3.train.json,  # The listener responses\nlisteners.csv     # The listener characteristics\n"})}),"\n",(0,s.jsx)(n.h3,{id:"listening-test-responses",children:"Listening Test Responses"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"CPC3.train.json"})," file contains a list of dictionaries, where each entry describes a listener's response to a signal. The fields are as follows:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",metastring:'title="CPC3.train.json"',children:' [\n    // ... etc\n {\n        "signal": "CEC1_E001_S08594_L0231",\n        "prompt": "I can\'t keep my cool and he does rattle me",\n        "response": "I can\'t keep my ",\n        "n_words": 10,\n        "words_correct": 4,\n        "correctness": 40.0\n },\n  // ... etc\n ]\n'})}),"\n",(0,s.jsx)(n.p,{children:"In this structure:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"signal"})," identifies the hearing aid output signal presented to the listener. You can use the signal name to determine the scene, system, and listener."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"prompt"})," is the transcription of the target sentence."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"response"}),' is the transcription of the listener\'s response ("#" indicates that the listener did not respond or indicated they did not understand any words).']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"n_words"})," indicates the total number of words in the target sentence."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"words_correct"})," reflects the number of words that the listener correctly identified."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"correctness"})," represents the percentage of words the listener correctly identified. ",(0,s.jsx)(n.strong,{children:"This is the number that you are asked to predict."})]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"listener-characteristics",children:"Listener Characteristics"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"listeners.csv"})," file provides information about the listener's hearing impairment severity (as per the 2021 WHO standard)."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-csv",metastring:'title="listeners.csv"',children:"listener_id,severity\nL0200,Moderate\nL0201,Mild\nL0202,Moderate\nL0207,Moderate\netc\n"})})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(o,{...e})}):o(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>c});var i=t(96540);const s={},r=i.createContext(s);function a(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);