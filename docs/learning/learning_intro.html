<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-learning/learning_intro" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.0.0">
<title data-rh="true">Learning | The Clarity Project</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://claritychallenge.github.io/docs/learning/learning_intro"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Learning | The Clarity Project"><meta data-rh="true" name="description" content="This pages contains some background information on the topics of speech intelligibility, hearing loss and objective measures."><meta data-rh="true" property="og:description" content="This pages contains some background information on the topics of speech intelligibility, hearing loss and objective measures."><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://claritychallenge.github.io/docs/learning/learning_intro"><link data-rh="true" rel="alternate" href="https://claritychallenge.github.io/docs/learning/learning_intro" hreflang="en"><link data-rh="true" rel="alternate" href="https://claritychallenge.github.io/docs/learning/learning_intro" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="The Clarity Project RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="The Clarity Project Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-198878187-1","auto"),ga("set","anonymizeIp",!0),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>







<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
<link rel="stylesheet" href="/js-datatable/css.min/bootstrap-table.min.css">
<link rel="stylesheet" href="/js-datatable/css.min/datatable.min.css">
<link rel="stylesheet" href="/react-bootstrap-table2.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
<script src="/bootstrap/bootstrap.bundle.min.js"></script>
<script src="https://cdn.jsdelivr.net/gh/pcooksey/bibtex-js@1.0.0/src/bibtex_js.min.js"></script><link rel="stylesheet" href="/assets/css/styles.da7967a1.css">
<script src="/assets/js/runtime~main.a1906a97.js" defer="defer"></script>
<script src="/assets/js/main.2eba30b6.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.png" alt="Clarity Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.png" alt="Clarity Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Clarity</b></a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Shortcuts</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/docs/cec3/cec3_intro">I want to learn more about the CEC3 challenge...</a></li><li><a class="dropdown__link" href="/docs/cpc2/cpc2_results">I want to see the results of CPC2 ...</a></li><li><a class="dropdown__link" href="/docs/cec2/cec2_download">I want to see the results of CEC2 ...</a></li><li><a href="https://github.com/claritychallenge/clarity" target="_blank" rel="noopener noreferrer" class="dropdown__link">I want to see the code on GitHub...<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Challenges</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/docs/cec3/cec3_intro">CEC3</a></li><li><a class="dropdown__link" href="/docs/cpc2/cpc2_intro">CPC2</a></li><li><a class="dropdown__link" href="/docs/icassp2023/icassp2023_intro">ICASSP 2023 Grand Challenge</a></li><li><a class="dropdown__link" href="/docs/cec2/cec2_intro">CEC2</a></li><li><a class="dropdown__link" href="/docs/cpc1/cpc1_intro">CPC1</a></li><li><a class="dropdown__link" href="/docs/cec1/cec1_intro">CEC1</a></li><li><a class="dropdown__link" href="/timeline">Future Challenges</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Workshops</a><ul class="dropdown__menu"><li><a href="https://claritychallenge.github.io/clarity2023-workshop/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Clarity 2023<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://claritychallenge.github.io/clarity2022-CEC2-workshop/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Clarity CEC2 2022, Dec<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://claritychallenge.github.io/clarity2022-workshop/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Clarity 2022, Jun<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://claritychallenge.github.io/clarity2021-workshop/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Clarity 2021<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Software</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/tutorials">Tutorials</a></li><li><a href="https://github.com/claritychallenge/clarity" target="_blank" rel="noopener noreferrer" class="dropdown__link">GitHub<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><a class="navbar__item navbar__link" href="/publications">Publications</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/learning/learning_intro">Learning</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">About Us</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/about">About Us</a></li><li><a class="dropdown__link" href="/contact">Contact Us</a></li><li><a class="dropdown__link" href="/timeline">Project timeline</a></li></ul></div><a class="navbar__item navbar__link" href="/blog">Latest</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Search" aria-label="Search" class="navbar__search-input search-bar"></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><main class="docMainContainer_TBSr docMainContainerEnhanced_lQrH"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Learning</h1></header><div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>About this page</div><div class="admonitionContent_BuS1"><p>This pages contains some background information on the topics of <strong>speech intelligibility</strong>, <strong>hearing loss</strong> and <strong>objective measures</strong>.</p></div></div>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="speech-intelligibility">Speech Intelligibility<a href="#speech-intelligibility" class="hash-link" aria-label="Direct link to Speech Intelligibility" title="Direct link to Speech Intelligibility">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="what-is-speech-intelligibility">What is Speech Intelligibility?<a href="#what-is-speech-intelligibility" class="hash-link" aria-label="Direct link to What is Speech Intelligibility?" title="Direct link to What is Speech Intelligibility?">​</a></h3>
<p>The term <a href="https://en.wikipedia.org/wiki/Intelligibility_(communication)" target="_blank" rel="noopener noreferrer">Speech Intelligibility</a> is generally used in two different ways. It can refer to how much speech is understood by a listener, or to the number of words correctly identified by a listener as a proportion or percentage of the total number of words. In the Clarity project, we are using the latter definition, i.e., the percentage of words in a sentence that a listener identified correctly. This percentage is the target for your prediction models.</p>
<p>Speech intelligibility captures how a listener&#x27;s ability to participate in conversation is changed when the speech signal is degraded, e.g., by background noise and room reverberation, or is processed, e.g., by a hearing aid. Your prediction model will need to incorporate a model of the hearing abilities of each listener.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="how-is-speech-intelligibility-measured-with-listeners">How is Speech Intelligibility measured with listeners?<a href="#how-is-speech-intelligibility-measured-with-listeners" class="hash-link" aria-label="Direct link to How is Speech Intelligibility measured with listeners?" title="Direct link to How is Speech Intelligibility measured with listeners?">​</a></h3>
<p>In the Clarity project, a set of listeners listen to a sentence and then say what words they heard. In this project, speech intelligibility is measured as the number of words identified correctly as a percentage of the total number of words in a sentence.</p>
<p>You might consider looking at <a href="https://www.sciencedirect.com/science/article/pii/S1877050918302187" target="_blank" rel="noopener noreferrer">other metrics</a>, such as Word Error Rate (WER), which picks up on, e.g., where listeners insert words not in the original sentence. You might do this if you think that an estimate of WER or other metrics would help your system to estimate speech intelligibility, as defined in the Clarity project.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="how-is-speech-intelligibility-objectively-measured-by-a-computer">How is Speech Intelligibility objectively measured by a computer?<a href="#how-is-speech-intelligibility-objectively-measured-by-a-computer" class="hash-link" aria-label="Direct link to How is Speech Intelligibility objectively measured by a computer?" title="Direct link to How is Speech Intelligibility objectively measured by a computer?">​</a></h3>
<p>When fitting a hearing aid, it would be beneficial for an audiologist to be able to use an objective measure of speech intelligibility to determine what signal processing algorithm(s) should be used to compensate for the listener&#x27;s hearing impairment. Objective measures are also useful when measured speech intelligibility scores are unavailable, such as when developing a machine learning-based hearing aid algorithm or some other speech enhancement method. Another advantage of non-intrusive measures is that they do not require time-alignment of processed and reference signals.</p>
<p>Objective measures - or metrics - of speech intelligibility are used to allow a computer to estimate the likely performance of humans in listening tests. The main goal of entries to the prediction challenge is to produce one of these measures that performs well for listeners with hearing loss. There are two broad classes of speech intelligibility models:</p>
<ul>
<li>Intrusive metrics (also known as double-ended) are most common. This is where the intelligibility is estimated by comparing the degraded or processed speech signal with the original clean speech signal.</li>
<li>Non-intrusive metrics (also known as single-ended or blind) are less well developed. This is where intelligibility is estimated from the degraded or processed speech signal alone.</li>
</ul>
<p>In the Clarity project, both types of metrics are of interest. Intrusive metrics will be more accurate in many cases. However, there are hearing aid processes where the speech content is shifted in frequency, which will defeat most current intrusive speech intelligibility metrics. We also hypothesise that there might be issues with intrusive metrics and machine learning approaches in hearing aids that revoice the original speech.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="what-speech-intelligibility-models-already-exist-and-what-are-they-used-for">What speech intelligibility models already exist and what are they used for?<a href="#what-speech-intelligibility-models-already-exist-and-what-are-they-used-for" class="hash-link" aria-label="Direct link to What speech intelligibility models already exist and what are they used for?" title="Direct link to What speech intelligibility models already exist and what are they used for?">​</a></h3>
<p>There aren&#x27;t many speech intelligibility models that consider hearing impairment, but one that does is <a href="https://www.sciencedirect.com/science/article/pii/S0167639320300431" target="_blank" rel="noopener noreferrer">HASPI by Kates and Arehart</a>. In this seminar from the first Clarity workshop, James Kates discusses speech intelligibility models with a focus on the ones he has developed. He also discusses the speech quality metric <a href="https://en.wikipedia.org/wiki/Hearing-Aid_Speech_Quality_Index" target="_blank" rel="noopener noreferrer">HASQI</a>. If you&#x27;re interested in using HASPI or HASQI for the challenge, James Kates has kindly made the <a target="_blank" href="/assets/files/HASPIv2_HASQIv2_HAAQIv1-90688098b8d9e90fdc1ee4516175688c.zip">MATLAB code</a> and <a target="_blank" href="/assets/files/Users_Guide_ver3-079c55157dae104c506c47dd0bf03565.zip">user guide</a> available for download.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/hp9NT1zkGz0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"></iframe>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Click arrow to see synopsis.</summary><div><div class="collapsibleContent_i85q"><p>Signal degradations, such as additive noise and nonlinear distortion, can reduce the intelligibility and quality of a speech signal. Predicting intelligibility and quality for hearing aids is especially difficult since these devices may contain intentional nonlinear distortion designed to make speech more audible to a hearing-impaired listener. This speech processing often takes the form of time-varying multichannel gain adjustments. Intelligibility and quality metrics used for hearing aids and hearing-impaired listeners must therefore consider the trade-offs between audibility and distortion introduced by hearing-aid speech envelope modifications. This presentation uses the Hearing Aid Speech Perception Index (HASPI) and the Hearing Aid Speech Quality Index (HASQI) to predict intelligibility and quality, respectively. These indices incorporate a model of the auditory periphery that can be adjusted to reflect hearing loss. They have been trained on intelligibility scores and quality ratings from both normal-hearing and hearing-impaired listeners for a wide variety of signal and processing conditions. The basics of the metrics are explained, and the metrics are then used to analyse the effects of additive noise on speech, to evaluate noise suppression algorithms, and to measure differences among commercial hearing aids.</p></div></div></details>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="hearing-loss">Hearing Loss<a href="#hearing-loss" class="hash-link" aria-label="Direct link to Hearing Loss" title="Direct link to Hearing Loss">​</a></h2>
<p>There are many types of hearing loss, but the focus of the Clarity project is the hearing loss that happens with ageing. This is a form of <a href="https://rnid.org.uk/information-and-support/hearing-loss/types-of-hearing-loss-and-deafness/" target="_blank" rel="noopener noreferrer">sensorineural hearing loss</a>.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="how-does-hearing-loss-affect-the-perception-of-audio-signals-and-how-do-modern-hearing-aids-process-sound-to-help-with-this">How does hearing loss affect the perception of audio signals, and how do modern hearing aids process sound to help with this?<a href="#how-does-hearing-loss-affect-the-perception-of-audio-signals-and-how-do-modern-hearing-aids-process-sound-to-help-with-this" class="hash-link" aria-label="Direct link to How does hearing loss affect the perception of audio signals, and how do modern hearing aids process sound to help with this?" title="Direct link to How does hearing loss affect the perception of audio signals, and how do modern hearing aids process sound to help with this?">​</a></h3>
<p>In this seminar from the first Clarity workshop, Karolina Smeds from ORCA Europe and WS Audiology discusses the effects of hearing loss and the hearing aid processing strategies that are typically used to counter the sensory deficits.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/waPONoYrf8Q" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"></iframe>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Details</summary><div><div class="collapsibleContent_i85q"><summary>Click arrow to see synposis.</summary><div><p>Hearing loss leads to several unwanted effects. Loss of audibility for soft sounds is one effect, but also when amplification is used to create audibility for soft sounds, many <a href="https://www.lexico.com/en/definition/suprathreshold" target="_blank" rel="noopener noreferrer">suprathreshold</a> deficits remain. The most common type of hearing loss is a <a href="https://www.lexico.com/definition/cochlear" target="_blank" rel="noopener noreferrer">cochlear</a> hearing loss, where haircells or nerve synapses in the cochlea are damaged. Ageing and noise exposure are the most common causes of cochlear hearing loss. This type of hearing loss is associated with atypical loudness perception and difficulties in noisy situations. Background noise masks for instance speech to a higher degree than for a person with healthy hair cells. This explains why listening to speech-in-noise (SPIN) is such an important topic to work on. A brief introduction to signal processing in hearing aids will be presented. With the use of frequency-specific amplification and compression (automatic gain control, AGC), hearing aids are usually doing a good job in compensating for reduced audibility and for atypical suprathreshold loudness perception. However, it is more difficult to compensate for the increased masking effect. Some examples of strategies will be presented. Finally, natural conversations in noise will be discussed. The balance between being able to have a conversation with a specific communication partner in a group of people and being able to switch attention if someone else starts to talk will be touched upon.</p></div></div></div></details>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="prediction-model">Prediction model<a href="#prediction-model" class="hash-link" aria-label="Direct link to Prediction model" title="Direct link to Prediction model">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="do-i-have-to-use-a-separate-hearing-loss-model">Do I have to use a separate hearing loss model?<a href="#do-i-have-to-use-a-separate-hearing-loss-model" class="hash-link" aria-label="Direct link to Do I have to use a separate hearing loss model?" title="Direct link to Do I have to use a separate hearing loss model?">​</a></h3>
<p>No is the short answer! In the baseline, we&#x27;ve used the Cambridge hearing loss model and a separate binaural speech intelligibility model. Another approach would be to create a single model that encapsulates the combined effects of hearing loss and speech perception.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="what-should-the-output-of-my-prediction-model-be">What should the output of my prediction model be?<a href="#what-should-the-output-of-my-prediction-model-be" class="hash-link" aria-label="Direct link to What should the output of my prediction model be?" title="Direct link to What should the output of my prediction model be?">​</a></h3>
<p>The output should include a predicted speech intelligibility score per input signal, specifically, an estimate of the number of words correct as a percentage of the total number of words in the signal.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="data">Data<a href="#data" class="hash-link" aria-label="Direct link to Data" title="Direct link to Data">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="do-you-have-suggestions-for-expanding-the-training-data">Do you have suggestions for expanding the training data?<a href="#do-you-have-suggestions-for-expanding-the-training-data" class="hash-link" aria-label="Direct link to Do you have suggestions for expanding the training data?" title="Direct link to Do you have suggestions for expanding the training data?">​</a></h3>
<p>The prediction challenge data is limited by having to get the ground truth from listening tests on people with a hearing loss. We look forward to seeing what approaches teams use to help overcome this limitation, such as using unsurpervised models, data augmentation or generating additional ground truth data using a pre-existing model. The baseline model includes a hearing loss and speech intelligibility model that could be used for creating additional pre-training data. There are other models that you might consider where code is available. None has been checked by the Clarity team.</p>
<ul>
<li><a href="https://www.fit.vut.cz/person/izmolikova/functions/.en#nav" target="_blank" rel="noopener noreferrer">Katerina Zmolikova</a> has made <a href="https://github.com/BUTSpeechFIT/torch_msbg_mbstoi" target="_blank" rel="noopener noreferrer">her Pytorch version of the baseline hearing impairment and speech intelligibility model available</a>. Both model fit a neural network framework, are faster but more approximate (see graphs on github).</li>
<li><a href="https://pubmed.ncbi.nlm.nih.gov/29554034/" target="_blank" rel="noopener noreferrer">HASQI and HASPI</a> are quality and speech intelligibility metrics designed to work for people with a hearing impairment. <a href="/docs/cpc1/taking_part/cpc1_faq#speech-intelligibility">James Kates explains more about these above</a>. <a target="_blank" href="/assets/files/HASPIv2_HASQIv2_HAAQIv1-90688098b8d9e90fdc1ee4516175688c.zip">MATLAB code HASPI v2 and HASQI v2</a> are available, along with the <a target="_blank" href="/assets/files/Users_Guide_ver3-079c55157dae104c506c47dd0bf03565.zip">user guide</a>.</li>
<li><a href="https://github.com/dhimasryan/STOI-Net" target="_blank" rel="noopener noreferrer">STOI-Net: A Deep Learning based Non-Intrusive Speech Intelligibility Assessment Model</a> by Ryandhimas Zezario et al. is monaural and non-intrusive using Python, Keras and TensorFlow. It doesn&#x27;t model the effect of hearing loss. An alternative is <a href="http://ah-andersen.net/code/" target="_blank" rel="noopener noreferrer">Asger Heidemann Andersen&#x27;s MATLAB code</a>.</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="missing-data">Missing data<a href="#missing-data" class="hash-link" aria-label="Direct link to Missing data" title="Direct link to Missing data">​</a></h3>
<p>We have audiograms for all our listening panel. But for other characterisations of hearing, only some of the panel have provided data. Therefore there is missing data that has to be dealt with.</p>
<ol>
<li>
<p>One approach to the missing data is to just ignore it and just use the audiograms. The problem with this approach is that audiograms only quantifies the hearing threshold, and our speech in noise audio samples were not played that quietly. Nevertheless, audiograms are the most common way of characterising hearing loss.</p>
</li>
<li>
<p>Alternatively, a method to use the partial data could be developed, and we expect this would help with speech intelligibility prediction. You will find plenty of data science blog posts, <a href="https://towardsdatascience.com/all-about-missing-data-handling-b94b8b5d2184" target="_blank" rel="noopener noreferrer">e.g. towards data science</a> discussing different approaches.</p>
</li>
</ol>
<p>A key question is whether the missing data is &#x27;missing at random&#x27; i.e. is the distribution of the missing data expected to be the same as that of the present data? For the prediction challenge, this would mean the missing triple-digit-test values are coming from some random sample of the listeners, who&#x27;d be no different from the listeners who did complete the triple-digital-test. Unfortunately, this might not be true, because the failure to complete the triple-digit-tests could well correlate with hearing loss (e.g. maybe older people with more hearing loss were less likely to do the test). The Clarity data is probably &#x27;missing not at random&#x27;.</p>
<p>One simple solution is to delete examples with missing data, but the loss of so much data probably makes this undesirable.</p>
<p>A more sophisticated approach is to fill gaps in data via <em>imputation</em> i.e. first estimate values for the missing data and then treat the dataset as complete. A couple of simple approaches for imputation are: (i) use the mean value from the dataset for missing values, and (ii) create a model to estimate the missing data from the audiograms. There are other approaches in data science that could be exploited such as coding the missing values into a &#x27;N/A&#x27; category within the input data.</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#speech-intelligibility" class="table-of-contents__link toc-highlight">Speech Intelligibility</a><ul><li><a href="#what-is-speech-intelligibility" class="table-of-contents__link toc-highlight">What is Speech Intelligibility?</a></li><li><a href="#how-is-speech-intelligibility-measured-with-listeners" class="table-of-contents__link toc-highlight">How is Speech Intelligibility measured with listeners?</a></li><li><a href="#how-is-speech-intelligibility-objectively-measured-by-a-computer" class="table-of-contents__link toc-highlight">How is Speech Intelligibility objectively measured by a computer?</a></li><li><a href="#what-speech-intelligibility-models-already-exist-and-what-are-they-used-for" class="table-of-contents__link toc-highlight">What speech intelligibility models already exist and what are they used for?</a></li></ul></li><li><a href="#hearing-loss" class="table-of-contents__link toc-highlight">Hearing Loss</a><ul><li><a href="#how-does-hearing-loss-affect-the-perception-of-audio-signals-and-how-do-modern-hearing-aids-process-sound-to-help-with-this" class="table-of-contents__link toc-highlight">How does hearing loss affect the perception of audio signals, and how do modern hearing aids process sound to help with this?</a></li></ul></li><li><a href="#prediction-model" class="table-of-contents__link toc-highlight">Prediction model</a><ul><li><a href="#do-i-have-to-use-a-separate-hearing-loss-model" class="table-of-contents__link toc-highlight">Do I have to use a separate hearing loss model?</a></li><li><a href="#what-should-the-output-of-my-prediction-model-be" class="table-of-contents__link toc-highlight">What should the output of my prediction model be?</a></li></ul></li><li><a href="#data" class="table-of-contents__link toc-highlight">Data</a><ul><li><a href="#do-you-have-suggestions-for-expanding-the-training-data" class="table-of-contents__link toc-highlight">Do you have suggestions for expanding the training data?</a></li><li><a href="#missing-data" class="table-of-contents__link toc-highlight">Missing data</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/cec3/cec3_intro">CEC3 Documentation</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/cpc2/cpc2_intro">CPC2 Documentation</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/icassp2023/icassp2023_intro">ICASSP 2023 Documentation</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/cec2/cec2_intro">CEC2 Documentation</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/cpc1/cpc1_intro">CPC1 Documentation</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/cec1/cec1_intro">CEC1 Documentation</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="http://claritychallenge.org" target="_blank" rel="noopener noreferrer" class="footer__link-item">The Clarity Project<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://groups.google.com/g/clarity-challenge" target="_blank" rel="noopener noreferrer" class="footer__link-item">Clarity Google Group<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="mailto:claritychallengecontact@gmail.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Email Us<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Challenge Updates</a></li><li class="footer__item"><a href="https://github.com/claritychallenge/clarity" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 The Clarity Team. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>